---
title: "downloading_data"
format: html
editor: visual
---

Ok, now we have a inventory of weather stations, that will be really useful when I want to know the stations for a specific country or when I want to find which station is closest to a given coordinate.

Let's move to actually download the precipitation data from NOAA's GHCNM <https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/>.

Let's read out station inventory.

```{r}
library(tidyverse)
library(tictoc)
library(curl)
station_inventory <- read_csv(
  file = "data/processed/stationsInventory.csv"
)
```

Let's say we want to download only data for weather stations in Cyprus (CY). Let's filter and see how that looks like.

```{r}
station_inventory %>% 
  filter(country == "CY") %>% 
  str()
```

Ok, so Cyprus has 10 weather stations, let's download data for all of these. The naive approach or brute-force way of doing this is copying and pasting code to download one file at a time, like this:

```{r}
download.file(
  url = "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/CY000176090.csv",
  destfile = "data/raw/weather_stations/CY000176090.csv"
)

download.file(
  url = "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/CYE00100065.csv",
  destfile = "data/raw/weather_stations/CYE00100065.csv"
)

download.file(
  url = "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/CYE00100071.csv",
  destfile = "data/raw/weather_stations/CYE00100071.csv"
)
```

But you see this is troublesome when you want to download more than 3 files. This is a good case for loops and functions! It is a good rule of thumb that if you need to do the same thing 3 times (or copy and paste something more than twice) you should write a loop instead.

Furthermore, if you use a block of code or a loop more than twice and its purpose can be clearly defined, you should encapsulate it in a function. This is related to a fundamental software development principle called DRY (Don't repeat yourself).

Besides enabling re-usability of your code which will result in less typing, functions will allow your code to be more concise and clear, will reduce possible errors, and allow your code to be modular, and then you can move parts of your code outside your analysis script.

Let's start with writing a for loop to download all 10 files from Cyprus' weather stations.

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
# Check the urls that the loop and paste0 are creating
country_stations <- station_inventory %>% filter(country == "CY") %>% pull(stationId)
for (station in country_stations) {
  print(paste0(noaa_url, station, ".csv"))
  }
```

This looks good, so now let's do the loop to download the files

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
folder_path <- "data/raw/weather_stations/"
country_stations <- station_inventory %>% 
  filter(country == "CY") %>% 
  pull(stationId)

for (station in country_stations) {
  download.file(
    url = paste0(noaa_url, station, ".csv"),
    destfile = paste0(folder_path, station, ".csv")
  )
}
```

There are multiple ways we can make this code for downloading data more efficient and readable. To start, let's see how to skip downloading data multiple times if the files are already in your computer. With this, we will learn about conditional statements, which are greatly useful when writing loops and functions.

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
folder_path <- "data/raw/weather_stations/"
country_stations <- station_inventory %>% 
  filter(country == "CY") %>% 
  pull(stationId)

for (station in country_stations) {
  # Path to the file in the iteration
  file_path <- paste0(folder_path, station, ".csv")
  
  # Check if file is already in our data path
  if (file.exists(file_path)) {
    print(paste0("File ", station, ".csv already in folder. Skipping"))
  } else {
    download.file(
    url = paste0(noaa_url, station, ".csv"),
    destfile = file_path,
    quiet = TRUE
  )
    print(paste0("File ", station, ".csv downloaded"))
  }
}
```

If you have multiple conditions, you would use a combination of if, else if, and else statements like this: if () {

} else if () {

} else {

}

Now, let's say you have thousands of files to download and you left your computer running a loop overnight. What happens if there is an error with one of the elements of your loop? Your code will crash and stop at the iteration where the error happened. This results in lost time, as the loop could have continued with iterations that had no errors.

To show this , we'll modify the second weather station in Cyprus, and then try to run our previous code.

```{r}
# Breaking our data so we can show an error when trying to download data for a non-existant station
station_inventory$stationId <- str_replace(station_inventory$stationId, "CYE00100065", "xxxxx")
```

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
folder_path <- "data/raw/weather_stations/"
country_stations <- station_inventory %>% 
  filter(country == "CY") %>% 
  pull(stationId)

for (station in country_stations) {
  # Path to the file in the iteration
  file_path <- paste0(folder_path, station, ".csv")
  
  # Check if file is already in our data path
  if (file.exists(file_path)) {
    print(paste0("File ", station, ".csv already in folder. Skipping to next"))
  } else {
    download.file(
    url = paste0(noaa_url, station, ".csv"),
    destfile = file_path,
    quiet = TRUE
  )
    print(paste0("File ", station, ".csv downloaded"))
  }
}
```

To prevent our code to break when there's an error, we'll use the tryCatch() function inside our loop to catch any error and handle it in a particular way. It works like and if-else if-else statement, where you say "If there is no error, do this. If there's an error do this other thing."

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
folder_path <- "data/raw/weather_stations/"
country_stations <- station_inventory %>% 
  filter(country == "cy") %>% 
  pull(stationId)

for (station in country_stations) {
  # Path to the file in the iteration
  file_path <- paste0(folder_path, station, ".csv")
  
  # Check if file is already in our data path
  if (file.exists(file_path)) {
    print(paste0("File ", station, ".csv already in folder. Skipping to next"))
  } else {
    
    tryCatch(
      expr = {download.file(url = paste0(noaa_url, station, ".csv"), destfile = file_path, quiet = TRUE)
        print(paste0("File ", station, ".csv downloaded"))
        },
      error = function(e) {
        print(paste0("There was an error trying to download data for stationId: ", station, ". Here is the error message: "))
        print(conditionMessage(e))
      }
    )
  }
}
```

But this loop is getting confusing, and this code only works if I want to download data for Cyprus. If I want to download data for another country I'd have to copy and paste, which doesn't comply with our DRY principle. To make our code modular, we'll start using functions. First we'll write a function to download one file and handle possible errors. Then, we'll write a function to filter the countries we are interested in and return the corresponding vector of stationIds. Then, we'll use the map() function to replace our loop and make our code more succinct.

The basic structure of a function is:

```{r}
my_function_name <- function(argument1, argument2) {
  result <- argument1+argument2
  return (result)
}
my_function_name(4, 6)
my_function_name(argument1 = 4, argument2 = 6)
```

We'll create a function their requires only one argument, the stationId, and then downloads monthly precipitation data from ghcnm, handling possible errors.

```{r}
single_download_noaa_ghcnm <- function(station) {
  noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
  folder_path <- "data/raw/weather_stations/"
  file_path <- paste0(folder_path, station, ".csv")
  if (file.exists(file_path)) {
    message <- paste0("File ", station, ".csv already in folder. Skipping to next")
  } else {
  tryCatch(
      {download.file(url = paste0(noaa_url, station, ".csv"), destfile = file_path, quiet = TRUE)
        message <- paste0("File ", station, ".csv downloaded")
          },
      error = function(e) {
        message <- paste0("There was an error trying to download data for stationId: ", station, ". Here is the error message: ")
        print(conditionMessage(e))
      }
    )
  }
  print(message)
}
```

Then you can create a function that filters only those stations in the countries you are interested, and runs the download function for each station.

```{r}
country_download_noaa_ghcnm <- function(data_path, countries) {
  station_inventory <- read_csv(data_path, show_col_types = FALSE)
  stationid_vector <- station_inventory %>% 
  filter(country %in% countries) %>% 
  pull(stationId)
  
  for (i in stationid_vector) {
    single_download_noaa_ghcnm(i)
  }
}
```

We can try it with another country, Eritrea (ER):

```{r}
country_download_noaa_ghcnm("data/processed/stationsInventory.csv",
                            c("ER"))
```

We'll learn one more useful thing about functions, default arguments. When creating a function, you can set default arguments, and give the user of the function the possibility to change the default behavior of a function.

For this example, we'll add a default argument print_result = FALSE in the single_download_noaa_ghcnm function, to not print the resulting message for the download of each file.

```{r}
single_download_noaa_ghcnm <- function(station, print_result = FALSE) {
  noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
  folder_path <- "data/raw/weather_stations/"
  file_path <- paste0(folder_path, station, ".csv")
  if (file.exists(file_path)) {
    message <- paste0("File ", station, ".csv already in folder. Skipping to next")
  } else {
  tryCatch(
      {download.file(url = paste0(noaa_url, station, ".csv"), destfile = file_path, quiet = TRUE)
        message <- paste0("File ", station, ".csv downloaded")
          },
      error = function(e) {
        message <- paste0("There was an error trying to download data for stationId: ", station, ". Here is the error message: ")
        print(conditionMessage(e))
      }
    )
  }
  if (print_result) {
    print(message)
  }
}
```

```{r}
country_download_noaa_ghcnm <- function(inventory_path, countries, print_result = FALSE) {
  station_inventory <- read_csv(inventory_path, show_col_types = FALSE)
  stationid_vector <- station_inventory %>% 
  filter(country %in% countries) %>% 
  pull(stationId)
  
  for (i in stationid_vector) {
    single_download_noaa_ghcnm(i, print_result)
  }
}
```

```{r}
country_download_noaa_ghcnm("data/processed/stationsInventory.csv",
                            c("CY", "ER"))
```

Now changing the default argument to print the result of each downloaded file.

```{r}
country_download_noaa_ghcnm("data/processed/stationsInventory.csv",
                            c("CY", "ER", "ST"),
                            print_result = TRUE)
```

This process of downloading files was only educational for practicing loops and functions. When you actually have to download multiple files from the internet, we recommend to use the "curl" package and its [multi_download function](https://jeroen.r-universe.dev/curl/doc/manual.html#multi_download), which has all this functionality of error-handling and concurrent downloads.

```{r}
noaa_url <- "https://www.ncei.noaa.gov/data/ghcnm/v4/precipitation/access/"
folder_path <- "data/raw/weather_stations/"

ids <- station_inventory %>% 
  filter(country == "TV") %>% 
  pull(stationId)

origins <- paste0(noaa_url, ids, ".csv")
dests <- paste0(folder_path, ids, ".csv")

results <- curl::multi_download(urls = origins, destfiles = dests)
```

Now you can make your code cleaner by moving some of this functions to a separate R script and calling this functions with source().
